{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:06:52.284751Z",
     "start_time": "2018-07-13T10:06:50.211Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#loading data in a dataframe\n",
    "df_data = sqlContext.read.format('com.databricks.spark.csv').\\\n",
    "options(header='true', inferschema='true').load('churn.csv')\n",
    "\n",
    "\n",
    "df_data.cache()\n",
    "df_data.head(1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 'state: string (nullable = true)\n",
      " |-- account_length: double (nullable = true)\n",
      " |-- area_code: double (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- international_plan: string (nullable = true)\n",
      " |-- voice_mail_plan: string (nullable = true)\n",
      " |-- number_vmail_messages: double (nullable = true)\n",
      " |-- total_day_minutes: double (nullable = true)\n",
      " |-- total_day_calls: double (nullable = true)\n",
      " |-- total_day_charge: double (nullable = true)\n",
      " |-- total_eve_minutes: double (nullable = true)\n",
      " |-- total_eve_calls: double (nullable = true)\n",
      " |-- total_eve_charge: double (nullable = true)\n",
      " |-- total_night_minutes: double (nullable = true)\n",
      " |-- total_night_calls: double (nullable = true)\n",
      " |-- total_night_charge: double (nullable = true)\n",
      " |-- total_intl_minutes: double (nullable = true)\n",
      " |-- total_intl_calls: double (nullable = true)\n",
      " |-- total_intl_charge: double (nullable = true)\n",
      " |-- number_customer_service_calls: double (nullable = true)\n",
      " |-- churned': string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:36.947997Z",
     "start_time": "2018-07-13T10:12:37.666Z"
    }
   },
   "outputs": [],
   "source": [
    "trainDF, testDF = df_data.randomSplit([.8,.2],seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:38.240934Z",
     "start_time": "2018-07-13T10:12:38.059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:38.554433Z",
     "start_time": "2018-07-13T10:12:38.432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:39.582876Z",
     "start_time": "2018-07-13T10:12:38.780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringIndexer_4e368afffebc0042573c"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler # see https://spark.apache.org/docs/latest/ml-features.html\n",
    "\n",
    "\n",
    "assembler1 = VectorAssembler(\n",
    "    inputCols = [\n",
    "        'number_customer_service_calls', \\\n",
    "        'total_night_minutes', \\\n",
    "        'total_day_minutes', \\\n",
    "        'total_eve_minutes', \\\n",
    "        'account_length'],\n",
    "    outputCol = 'features')\n",
    "\n",
    "# Transform labels\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "label_indexer = StringIndexer(inputCol = 'churned\\'', outputCol = 'label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:42.200103Z",
     "start_time": "2018-07-13T10:12:39.139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "classifier1 = LogisticRegression(labelCol = 'label', featuresCol = 'features')\n",
    "\n",
    "pipeline1 = Pipeline(stages=[assembler1, label_indexer, classifier1]) \n",
    "# see https://spark.apache.org/docs/latest/ml-pipeline.html\n",
    "\n",
    "model1 = pipeline1.fit(trainDF)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:43.488254Z",
     "start_time": "2018-07-13T10:12:39.446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 'state: string (nullable = true)\n",
      " |-- account_length: double (nullable = true)\n",
      " |-- area_code: double (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- international_plan: string (nullable = true)\n",
      " |-- voice_mail_plan: string (nullable = true)\n",
      " |-- number_vmail_messages: double (nullable = true)\n",
      " |-- total_day_minutes: double (nullable = true)\n",
      " |-- total_day_calls: double (nullable = true)\n",
      " |-- total_day_charge: double (nullable = true)\n",
      " |-- total_eve_minutes: double (nullable = true)\n",
      " |-- total_eve_calls: double (nullable = true)\n",
      " |-- total_eve_charge: double (nullable = true)\n",
      " |-- total_night_minutes: double (nullable = true)\n",
      " |-- total_night_calls: double (nullable = true)\n",
      " |-- total_night_charge: double (nullable = true)\n",
      " |-- total_intl_minutes: double (nullable = true)\n",
      " |-- total_intl_calls: double (nullable = true)\n",
      " |-- total_intl_charge: double (nullable = true)\n",
      " |-- number_customer_service_calls: double (nullable = true)\n",
      " |-- churned': string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7420194416869594"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "predictionsTrain1 = model1.transform(trainDF) # get a prediction\n",
    "predictionsTrain1.printSchema()\n",
    "evaluatorTrain1 = BinaryClassificationEvaluator()\n",
    "#Evaluator for binary classification, which expects two input columns: rawPrediction and label.\n",
    "evaluatorTrain1.evaluate(predictionsTrain1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:44.373989Z",
     "start_time": "2018-07-13T10:12:39.770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803118176855909"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsTest1 = model1.transform(testDF)\n",
    "evaluatorTest1 = BinaryClassificationEvaluator()\n",
    "evaluatorTest1.evaluate(predictionsTest1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:47.132655Z",
     "start_time": "2018-07-13T10:12:40.051Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's redo the analysis eliminating one feature\n",
    "assembler2 = VectorAssembler(\n",
    "    inputCols = [\n",
    "        'total_night_minutes', \\\n",
    "        'total_day_minutes', \\\n",
    "        'total_eve_minutes', \\\n",
    "        'account_length'],\n",
    "    outputCol = 'features')\n",
    "\n",
    "pipeline2 = Pipeline(stages=[assembler2, label_indexer, classifier1])\n",
    "\n",
    "model2 = pipeline2.fit(trainDF)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:48.266013Z",
     "start_time": "2018-07-13T10:12:40.331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6430179160765926"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsTrain2 = model2.transform(trainDF)\n",
    "evaluatorTrain2 = BinaryClassificationEvaluator()\n",
    "evaluatorTrain2.evaluate(predictionsTrain2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T11:12:49.979034Z",
     "start_time": "2018-07-13T10:12:40.973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6686254776200852"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsTest2 = model2.transform(testDF)\n",
    "evaluatorTest2 = BinaryClassificationEvaluator()\n",
    "evaluatorTest2.evaluate(predictionsTest2)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
